{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KLtnCYzGrNh",
        "outputId": "b3d7912c-1f9f-4c19-d584-f3602ada384a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/MyDrive/Kdigital/final_data.csv')  #기업 데이터(공개 불가)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import graphviz\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "xEWv1lJaG5_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 1:]\n",
        "y = data['TARGET']\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X = pca.fit_transform(X)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "X_train_over, y_train_over = smote.fit_resample(X, y)\n",
        "print(\"SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : \", X.shape, y.shape)\n",
        "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :', X_train_over.shape, y_train_over.shape)\n",
        "print('SMOTE 적용 후 전의 분포 :\\n',pd.Series(y).value_counts() )\n",
        "print('SMOTE 적용 후 값의 분포 :\\n',pd.Series(y_train_over).value_counts() )\n",
        "\n",
        "y = y.replace(1,-1)\n",
        "y = y.replace(0,1)\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=49)\n",
        "Kfold = StratifiedKFold(n_splits=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zawaNy9HEvd",
        "outputId": "f2613bc2-4a7d-4bbb-ff7c-ab83842f8069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE 적용 전 학습용 피처/레이블 데이터 세트 :  (10642, 2) (10642,)\n",
            "SMOTE 적용 후 학습용 피처/레이블 데이터 세트 : (20000, 2) (20000,)\n",
            "SMOTE 적용 후 전의 분포 :\n",
            " 0    10000\n",
            "1      642\n",
            "Name: TARGET, dtype: int64\n",
            "SMOTE 적용 후 값의 분포 :\n",
            " 0    10000\n",
            "1    10000\n",
            "Name: TARGET, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(model_name, train_x, train_y, KFold):\n",
        "  if model_name == 'IForest':\n",
        "    model = IsolationForest()\n",
        "    param = {'contamination':[0.1, 0.3, 0.5],\n",
        "             'n_estimators' : [50, 75, 100],\n",
        "             'max_features' : [0.4, 0.7, 1]}\n",
        "\n",
        "  elif model_name == 'oc_svm':\n",
        "    model = OneClassSVM(max_iter=100)\n",
        "    param = {'kernel' : ['rbf', 'sigmoid', 'poly', 'linear'],\n",
        "             'gamma' : [0.3, 0.6, 0.9]}\n",
        "\n",
        "  elif model_name == 'LogisticRegression':\n",
        "    model = LogisticRegression()\n",
        "    param = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
        "             'l1_ratio' : [0.3, 0.5, 0.7, 0.9],\n",
        "             'solver' : ['newton_cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "\n",
        "  elif model_name == 'DecisionTree':\n",
        "    model = DecisionTreeClassifier()\n",
        "    param = {'criterion' : ['gini', 'entropy', 'log_loss'],\n",
        "             'max_depth' : [3, 6, 9, 10],\n",
        "             'min_samples_split' : [1, 2, 3],\n",
        "             'min_samples_leaf' : [1, 2]}\n",
        "\n",
        "  elif model_name == 'LGBM':\n",
        "    model = LGBMClassifier()\n",
        "    param = {'boosting_type':['gbdt', 'dart', 'goss', 'rf'],\n",
        "             'n_estimators' : [50, 75, 100]}\n",
        "\n",
        "\n",
        "  grid_search = GridSearchCV(model,\n",
        "                              param_grid = param,\n",
        "                              cv = Kfold,\n",
        "                              scoring=['f1', 'precision', 'recall', 'accuracy'],\n",
        "                              refit = 'recall',\n",
        "                              n_jobs = -1)\n",
        "  grid_search.fit(train_x, train_y)\n",
        "\n",
        "  grid_search_results = pd.DataFrame(grid_search.cv_results_)\n",
        "  grid_search_results = grid_search_results.sort_values(by = 'mean_test_f1',\n",
        "                                                     ascending = False)\n",
        "\n",
        "  print(grid_search_results[['params', 'mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'mean_test_f1']])\n",
        "\n",
        "  best_model = grid_search.best_estimator_\n",
        "\n",
        "  return best_model"
      ],
      "metadata": {
        "id": "b9m7QzkIHGKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluation(y_test, pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "\n",
        "\n",
        "    print('Confusion Matrix')\n",
        "    print(confusion)\n",
        "    print('accuracy: {0:.4f}, precision: {1:.4f}, recall: {2:.4f}, f1: {3:.4f}'.format( accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "W1V4n_h3HKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = make_model('oc_svm', train_x, train_y, Kfold)\n",
        "Iforest_model = make_model('IForest', train_x, train_y, Kfold)\n",
        "logistic_model = make_model('LogisticRegression', train_x, train_y, Kfold)\n",
        "tree_model = make_model('DecisionTree', train_x, train_y, Kfold)\n",
        "lbgm_model = make_model('LGBM', train_x, train_y, Kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmeUuMssHKy3",
        "outputId": "89047d63-51ed-45c2-db7b-09aa620518b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 params  mean_test_accuracy  \\\n",
            "3    {'gamma': 0.3, 'kernel': 'linear'}            0.781447   \n",
            "7    {'gamma': 0.6, 'kernel': 'linear'}            0.781447   \n",
            "11   {'gamma': 0.9, 'kernel': 'linear'}            0.781447   \n",
            "0       {'gamma': 0.3, 'kernel': 'rbf'}            0.641831   \n",
            "4       {'gamma': 0.6, 'kernel': 'rbf'}            0.623976   \n",
            "8       {'gamma': 0.9, 'kernel': 'rbf'}            0.622500   \n",
            "1   {'gamma': 0.3, 'kernel': 'sigmoid'}            0.406229   \n",
            "9   {'gamma': 0.9, 'kernel': 'sigmoid'}            0.400322   \n",
            "5   {'gamma': 0.6, 'kernel': 'sigmoid'}            0.380991   \n",
            "2      {'gamma': 0.3, 'kernel': 'poly'}            0.365821   \n",
            "6      {'gamma': 0.6, 'kernel': 'poly'}            0.362062   \n",
            "10     {'gamma': 0.9, 'kernel': 'poly'}            0.351994   \n",
            "\n",
            "    mean_test_precision  mean_test_recall  mean_test_f1  \n",
            "3              0.938180          0.821712      0.875738  \n",
            "7              0.938180          0.821712      0.875738  \n",
            "11             0.938180          0.821712      0.875738  \n",
            "0              0.944059          0.657857      0.775369  \n",
            "4              0.943059          0.638429      0.761381  \n",
            "8              0.943307          0.636572      0.760135  \n",
            "1              0.947372          0.389570      0.550827  \n",
            "9              0.932330          0.390569      0.546731  \n",
            "5              0.943987          0.362569      0.521930  \n",
            "2              0.938377          0.347474      0.350831  \n",
            "6              0.894865          0.343474      0.342992  \n",
            "10             0.480257          0.331476      0.322503  \n",
            "                                               params  mean_test_accuracy  \\\n",
            "2   {'contamination': 0.1, 'max_features': 0.4, 'n...            0.861055   \n",
            "5   {'contamination': 0.1, 'max_features': 0.7, 'n...            0.858639   \n",
            "8   {'contamination': 0.1, 'max_features': 1, 'n_e...            0.858504   \n",
            "0   {'contamination': 0.1, 'max_features': 0.4, 'n...            0.857968   \n",
            "6   {'contamination': 0.1, 'max_features': 1, 'n_e...            0.856759   \n",
            "1   {'contamination': 0.1, 'max_features': 0.4, 'n...            0.855685   \n",
            "7   {'contamination': 0.1, 'max_features': 1, 'n_e...            0.853940   \n",
            "4   {'contamination': 0.1, 'max_features': 0.7, 'n...            0.853537   \n",
            "3   {'contamination': 0.1, 'max_features': 0.7, 'n...            0.852866   \n",
            "11  {'contamination': 0.3, 'max_features': 0.4, 'n...            0.683447   \n",
            "16  {'contamination': 0.3, 'max_features': 1, 'n_e...            0.683447   \n",
            "17  {'contamination': 0.3, 'max_features': 1, 'n_e...            0.682239   \n",
            "13  {'contamination': 0.3, 'max_features': 0.7, 'n...            0.679957   \n",
            "14  {'contamination': 0.3, 'max_features': 0.7, 'n...            0.680091   \n",
            "10  {'contamination': 0.3, 'max_features': 0.4, 'n...            0.677138   \n",
            "12  {'contamination': 0.3, 'max_features': 0.7, 'n...            0.677406   \n",
            "15  {'contamination': 0.3, 'max_features': 1, 'n_e...            0.675527   \n",
            "9   {'contamination': 0.3, 'max_features': 0.4, 'n...            0.675661   \n",
            "20  {'contamination': 0.5, 'max_features': 0.4, 'n...            0.510001   \n",
            "18  {'contamination': 0.5, 'max_features': 0.4, 'n...            0.504229   \n",
            "25  {'contamination': 0.5, 'max_features': 1, 'n_e...            0.501410   \n",
            "19  {'contamination': 0.5, 'max_features': 0.4, 'n...            0.502081   \n",
            "24  {'contamination': 0.5, 'max_features': 1, 'n_e...            0.500604   \n",
            "23  {'contamination': 0.5, 'max_features': 0.7, 'n...            0.496711   \n",
            "26  {'contamination': 0.5, 'max_features': 1, 'n_e...            0.495234   \n",
            "22  {'contamination': 0.5, 'max_features': 0.7, 'n...            0.492415   \n",
            "21  {'contamination': 0.5, 'max_features': 0.7, 'n...            0.491475   \n",
            "\n",
            "    mean_test_precision  mean_test_recall  mean_test_f1  \n",
            "2              0.944159          0.905715      0.924535  \n",
            "5              0.942823          0.904429      0.923217  \n",
            "8              0.943471          0.903571      0.923080  \n",
            "0              0.943968          0.902428      0.922727  \n",
            "6              0.943629          0.901428      0.922042  \n",
            "1              0.943692          0.900143      0.921401  \n",
            "7              0.943319          0.898571      0.920398  \n",
            "4              0.943018          0.898428      0.920181  \n",
            "3              0.942054          0.898714      0.919867  \n",
            "11             0.944491          0.704571      0.807023  \n",
            "16             0.944837          0.704285      0.806962  \n",
            "17             0.944737          0.702999      0.806092  \n",
            "13             0.943210          0.701713      0.804687  \n",
            "14             0.944893          0.700427      0.804461  \n",
            "10             0.943327          0.698427      0.802551  \n",
            "12             0.945429          0.696999      0.802321  \n",
            "15             0.942302          0.697428      0.801569  \n",
            "9              0.944065          0.696142      0.801287  \n",
            "20             0.946551          0.507287      0.660465  \n",
            "18             0.943689          0.502430      0.655680  \n",
            "25             0.942354          0.500142      0.653316  \n",
            "19             0.945458          0.498999      0.653172  \n",
            "24             0.944734          0.497713      0.651876  \n",
            "23             0.942609          0.494572      0.648728  \n",
            "26             0.941486          0.493573      0.647570  \n",
            "22             0.942345          0.489858      0.644578  \n",
            "21             0.942270          0.488857      0.643684  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "120 fits failed out of a total of 240.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "48 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 436, in _check_solver\n",
            "    % (all_solvers, solver)\n",
            "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton_cg.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.96892518        nan 0.96892518        nan\n",
            " 0.96892518 0.96892518 0.96892518 0.96892518        nan        nan\n",
            "        nan        nan 0.96892518        nan 0.96892518        nan\n",
            " 0.96892518 0.96892518        nan        nan 0.96892518        nan\n",
            " 0.96892518        nan 0.96892518 0.96892518 0.96892518 0.96892518\n",
            "        nan        nan        nan        nan 0.96892518        nan\n",
            " 0.96892518        nan 0.96892518 0.96892518        nan        nan\n",
            " 0.96892518        nan 0.96892518        nan 0.96892518 0.96892518\n",
            " 0.96892518 0.96892518        nan        nan        nan        nan\n",
            " 0.96892518        nan 0.96892518        nan 0.96892518 0.96892518\n",
            "        nan        nan 0.96892518        nan 0.96892518        nan\n",
            " 0.96892518 0.96892518 0.96892518 0.96892518        nan        nan\n",
            "        nan        nan 0.96892518        nan 0.96892518        nan\n",
            " 0.96892518 0.96892518]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.93972345        nan 0.93972345        nan\n",
            " 0.93972345 0.93972345 0.93972345 0.93972345        nan        nan\n",
            "        nan        nan 0.93972345        nan 0.93972345        nan\n",
            " 0.93972345 0.93972345        nan        nan 0.93972345        nan\n",
            " 0.93972345        nan 0.93972345 0.93972345 0.93972345 0.93972345\n",
            "        nan        nan        nan        nan 0.93972345        nan\n",
            " 0.93972345        nan 0.93972345 0.93972345        nan        nan\n",
            " 0.93972345        nan 0.93972345        nan 0.93972345 0.93972345\n",
            " 0.93972345 0.93972345        nan        nan        nan        nan\n",
            " 0.93972345        nan 0.93972345        nan 0.93972345 0.93972345\n",
            "        nan        nan 0.93972345        nan 0.93972345        nan\n",
            " 0.93972345 0.93972345 0.93972345 0.93972345        nan        nan\n",
            "        nan        nan 0.93972345        nan 0.93972345        nan\n",
            " 0.93972345 0.93972345]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan  1. nan  1. nan  1.  1.  1.  1. nan nan nan nan  1. nan  1. nan\n",
            "  1.  1. nan nan  1. nan  1. nan  1.  1.  1.  1. nan nan nan nan  1. nan\n",
            "  1. nan  1.  1. nan nan  1. nan  1. nan  1.  1.  1.  1. nan nan nan nan\n",
            "  1. nan  1. nan  1.  1. nan nan  1. nan  1. nan  1.  1.  1.  1. nan nan\n",
            " nan nan  1. nan  1. nan  1.  1.]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               params  mean_test_accuracy  \\\n",
            "2   {'l1_ratio': 0.3, 'penalty': 'l1', 'solver': '...            0.939723   \n",
            "4   {'l1_ratio': 0.3, 'penalty': 'l1', 'solver': '...            0.939723   \n",
            "46  {'l1_ratio': 0.7, 'penalty': 'l2', 'solver': '...            0.939723   \n",
            "47  {'l1_ratio': 0.7, 'penalty': 'l2', 'solver': '...            0.939723   \n",
            "48  {'l1_ratio': 0.7, 'penalty': 'l2', 'solver': '...            0.939723   \n",
            "..                                                ...                 ...   \n",
            "71  {'l1_ratio': 0.9, 'penalty': 'elasticnet', 'so...                 NaN   \n",
            "72  {'l1_ratio': 0.9, 'penalty': 'elasticnet', 'so...                 NaN   \n",
            "73  {'l1_ratio': 0.9, 'penalty': 'elasticnet', 'so...                 NaN   \n",
            "75  {'l1_ratio': 0.9, 'penalty': 'none', 'solver':...                 NaN   \n",
            "77  {'l1_ratio': 0.9, 'penalty': 'none', 'solver':...                 NaN   \n",
            "\n",
            "    mean_test_precision  mean_test_recall  mean_test_f1  \n",
            "2              0.939723               1.0      0.968925  \n",
            "4              0.939723               1.0      0.968925  \n",
            "46             0.939723               1.0      0.968925  \n",
            "47             0.939723               1.0      0.968925  \n",
            "48             0.939723               1.0      0.968925  \n",
            "..                  ...               ...           ...  \n",
            "71                  NaN               NaN           NaN  \n",
            "72                  NaN               NaN           NaN  \n",
            "73                  NaN               NaN           NaN  \n",
            "75                  NaN               NaN           NaN  \n",
            "77                  NaN               NaN           NaN  \n",
            "\n",
            "[80 rows x 5 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "120 fits failed out of a total of 216.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "72 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "48 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
            "    criterion = CRITERIA_CLF[self.criterion](\n",
            "KeyError: 'log_loss'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.96847888 0.96847888        nan 0.96841626 0.96841626\n",
            "        nan 0.96796515 0.96796515        nan 0.96823857 0.96823857\n",
            "        nan 0.96607132 0.96600025        nan 0.96433604 0.96440824\n",
            "        nan 0.9646233  0.9646233         nan 0.96082851 0.96039346\n",
            "        nan 0.9685551  0.9685551         nan 0.96849241 0.96849241\n",
            "        nan 0.96820749 0.9679924         nan 0.96806878 0.96807333\n",
            "        nan 0.96677302 0.96662451        nan 0.96531875 0.96538038\n",
            "        nan 0.96560753 0.96539153        nan 0.96335522 0.96356723\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.94014844 0.94014844        nan 0.93990311 0.93990311\n",
            "        nan 0.94044745 0.94044745        nan 0.94083561 0.94083561\n",
            "        nan 0.94095466 0.94094632        nan 0.94088159 0.94088949\n",
            "        nan 0.94103332 0.94103332        nan 0.94109829 0.94093047\n",
            "        nan 0.94003773 0.94003773        nan 0.93979301 0.93979301\n",
            "        nan 0.94166984 0.94164626        nan 0.94153505 0.94141525\n",
            "        nan 0.94151072 0.94161419        nan 0.94171102 0.94195907\n",
            "        nan 0.94174489 0.94172137        nan 0.94186172 0.94200571\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.99857129 0.99857129        nan 0.99871416 0.99871416\n",
            "        nan 0.99714263 0.99714263        nan 0.99728575 0.99728575\n",
            "        nan 0.99257141 0.99242847        nan 0.9890002  0.98914302\n",
            "        nan 0.98942884 0.98942884        nan 0.98142898 0.98071502\n",
            "        nan 0.99885704 0.99885704        nan 0.99899992 0.99899992\n",
            "        nan 0.99628567 0.99585704        nan 0.9961428  0.99628567\n",
            "        nan 0.99342849 0.99299992        nan 0.99014273 0.98999986\n",
            "        nan 0.99071418 0.99028555        nan 0.98585684 0.98614259\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.93891798 0.93891798        nan 0.93878373 0.93878373\n",
            "        nan 0.93797825 0.93797825        nan 0.93851524 0.93851524\n",
            "        nan 0.93448785 0.9343536         nan 0.93126594 0.93140019\n",
            "        nan 0.93180293 0.93180293        nan 0.92482212 0.92401665\n",
            "        nan 0.93905222 0.93905222        nan 0.93891798 0.93891798\n",
            "        nan 0.93851524 0.9381125         nan 0.93824674 0.93824674\n",
            "        nan 0.93583031 0.93556182        nan 0.93314539 0.93327963\n",
            "        nan 0.93368237 0.93327963        nan 0.92952074 0.92992348\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               params  mean_test_accuracy  \\\n",
            "25  {'criterion': 'entropy', 'max_depth': 3, 'min_...            0.939052   \n",
            "26  {'criterion': 'entropy', 'max_depth': 3, 'min_...            0.939052   \n",
            "29  {'criterion': 'entropy', 'max_depth': 3, 'min_...            0.938918   \n",
            "28  {'criterion': 'entropy', 'max_depth': 3, 'min_...            0.938918   \n",
            "2   {'criterion': 'gini', 'max_depth': 3, 'min_sam...            0.938918   \n",
            "..                                                ...                 ...   \n",
            "67  {'criterion': 'log_loss', 'max_depth': 10, 'mi...                 NaN   \n",
            "68  {'criterion': 'log_loss', 'max_depth': 10, 'mi...                 NaN   \n",
            "69  {'criterion': 'log_loss', 'max_depth': 10, 'mi...                 NaN   \n",
            "70  {'criterion': 'log_loss', 'max_depth': 10, 'mi...                 NaN   \n",
            "71  {'criterion': 'log_loss', 'max_depth': 10, 'mi...                 NaN   \n",
            "\n",
            "    mean_test_precision  mean_test_recall  mean_test_f1  \n",
            "25             0.940038          0.998857      0.968555  \n",
            "26             0.940038          0.998857      0.968555  \n",
            "29             0.939793          0.999000      0.968492  \n",
            "28             0.939793          0.999000      0.968492  \n",
            "2              0.940148          0.998571      0.968479  \n",
            "..                  ...               ...           ...  \n",
            "67                  NaN               NaN           NaN  \n",
            "68                  NaN               NaN           NaN  \n",
            "69                  NaN               NaN           NaN  \n",
            "70                  NaN               NaN           NaN  \n",
            "71                  NaN               NaN           NaN  \n",
            "\n",
            "[72 rows x 5 columns]\n",
            "                                            params  mean_test_accuracy  \\\n",
            "3    {'boosting_type': 'dart', 'n_estimators': 50}            0.939723   \n",
            "4    {'boosting_type': 'dart', 'n_estimators': 75}            0.939723   \n",
            "5   {'boosting_type': 'dart', 'n_estimators': 100}            0.939589   \n",
            "0    {'boosting_type': 'gbdt', 'n_estimators': 50}            0.939321   \n",
            "6    {'boosting_type': 'goss', 'n_estimators': 50}            0.939321   \n",
            "7    {'boosting_type': 'goss', 'n_estimators': 75}            0.938918   \n",
            "1    {'boosting_type': 'gbdt', 'n_estimators': 75}            0.938649   \n",
            "8   {'boosting_type': 'goss', 'n_estimators': 100}            0.937844   \n",
            "2   {'boosting_type': 'gbdt', 'n_estimators': 100}            0.937710   \n",
            "9      {'boosting_type': 'rf', 'n_estimators': 50}                 NaN   \n",
            "10     {'boosting_type': 'rf', 'n_estimators': 75}                 NaN   \n",
            "11    {'boosting_type': 'rf', 'n_estimators': 100}                 NaN   \n",
            "\n",
            "    mean_test_precision  mean_test_recall  mean_test_f1  \n",
            "3              0.939723          1.000000      0.968925  \n",
            "4              0.939723          1.000000      0.968925  \n",
            "5              0.939715          0.999857      0.968854  \n",
            "0              0.939699          0.999571      0.968711  \n",
            "6              0.939817          0.999428      0.968707  \n",
            "7              0.939911          0.998857      0.968488  \n",
            "1              0.939659          0.998857      0.968354  \n",
            "8              0.939847          0.997714      0.967916  \n",
            "2              0.939838          0.997572      0.967845  \n",
            "9                   NaN               NaN           NaN  \n",
            "10                  NaN               NaN           NaN  \n",
            "11                  NaN               NaN           NaN  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "9 fits failed out of a total of 36.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\", line 744, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\", line 544, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\", line 197, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\", line 1554, in __init__\n",
            "    ctypes.byref(self.handle)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\", line 46, in _safe_call\n",
            "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
            "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /__w/1/s/python-package/compile/src/boosting/rf.hpp, line 28 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.96871102 0.96835386 0.96784465 0.96892518 0.96892518 0.96885379\n",
            " 0.96870653 0.96848782 0.96791594        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93969916 0.93965873 0.93983846 0.93972345 0.93972345 0.93971534\n",
            " 0.93981715 0.93991121 0.93984651        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.99957143 0.99885729 0.99757151 1.         1.         0.99985712\n",
            " 0.99942849 0.9988571  0.9977142         nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93932071 0.93864948 0.93770976 0.93972345 0.93972345 0.93958921\n",
            " 0.93932071 0.93891798 0.93784401        nan        nan        nan]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train_svm = svm_model.predict(train_x)\n",
        "pred_test_svm = svm_model.predict(test_x)\n",
        "\n",
        "model_evaluation(train_y, pred_train_svm)\n",
        "model_evaluation(test_y, pred_test_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5grIYwCMnvj",
        "outputId": "430c231c-9f1b-4657-8a98-5ef39d06ccc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[ 374   75]\n",
            " [6144  856]]\n",
            "accuracy: 0.1651, precision: 0.9194, recall: 0.1223, f1: 0.2159\n",
            "Confusion Matrix\n",
            "[[ 162   31]\n",
            " [2578  422]]\n",
            "accuracy: 0.1829, precision: 0.9316, recall: 0.1407, f1: 0.2444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train_Iforest = Iforest_model.predict(train_x)\n",
        "pred_test_Iforest = Iforest_model.predict(test_x)\n",
        "\n",
        "model_evaluation(train_y, pred_train_Iforest)\n",
        "model_evaluation(test_y, pred_test_Iforest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sDPJscrNp1G",
        "outputId": "831d1537-747e-4631-d453-1658b97dda6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[  74  375]\n",
            " [ 671 6329]]\n",
            "accuracy: 0.8596, precision: 0.9441, recall: 0.9041, f1: 0.9237\n",
            "Confusion Matrix\n",
            "[[  22  171]\n",
            " [ 275 2725]]\n",
            "accuracy: 0.8603, precision: 0.9410, recall: 0.9083, f1: 0.9244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train_logistic = logistic_model.predict(train_x)\n",
        "pred_test_logistic = logistic_model.predict(test_x)\n",
        "\n",
        "model_evaluation(train_y, pred_train_logistic)\n",
        "model_evaluation(test_y, pred_test_logistic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP3NAFtWNrYG",
        "outputId": "12f24c92-4c25-466e-d6b7-12dd0958bee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[   0  449]\n",
            " [   0 7000]]\n",
            "accuracy: 0.9397, precision: 0.9397, recall: 1.0000, f1: 0.9689\n",
            "Confusion Matrix\n",
            "[[   0  193]\n",
            " [   0 3000]]\n",
            "accuracy: 0.9396, precision: 0.9396, recall: 1.0000, f1: 0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train_tree = tree_model.predict(train_x)\n",
        "pred_test_tree = tree_model.predict(test_x)\n",
        "\n",
        "model_evaluation(train_y, pred_train_tree)\n",
        "model_evaluation(test_y, pred_test_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvKtz255N-30",
        "outputId": "df4af070-6030-445d-f197-b2d386639859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[   5  444]\n",
            " [   1 6999]]\n",
            "accuracy: 0.9403, precision: 0.9403, recall: 0.9999, f1: 0.9692\n",
            "Confusion Matrix\n",
            "[[   1  192]\n",
            " [   3 2997]]\n",
            "accuracy: 0.9389, precision: 0.9398, recall: 0.9990, f1: 0.9685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train_lbgm = lbgm_model.predict(train_x)\n",
        "pred_test_lbgm = lbgm_model.predict(test_x)\n",
        "\n",
        "model_evaluation(train_y, pred_train_lbgm)\n",
        "model_evaluation(test_y, pred_test_lbgm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb8J7eQdOJtN",
        "outputId": "5702ea8f-9caa-46b3-b581-d94087e721bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[   2  447]\n",
            " [   0 7000]]\n",
            "accuracy: 0.9400, precision: 0.9400, recall: 1.0000, f1: 0.9691\n",
            "Confusion Matrix\n",
            "[[   0  193]\n",
            " [   0 3000]]\n",
            "accuracy: 0.9396, precision: 0.9396, recall: 1.0000, f1: 0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PfTp1Ju9OjJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
